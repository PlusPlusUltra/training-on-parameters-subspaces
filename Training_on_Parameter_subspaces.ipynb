{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Training on Parameter subspaces"
      ],
      "metadata": {
        "id": "OnSvbAz_CLMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "SrT0Svr-CP-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYrXvMRQwJEn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "from math import sqrt\n",
        "import time\n",
        "from sympy import fwht\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import scipy\n",
        "import numpy as np\n",
        "from scipy.linalg import orth\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions"
      ],
      "metadata": {
        "id": "n5EhMGynCToa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_matrix (D,d): #this returns a dense projection matrix\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  return mat"
      ],
      "metadata": {
        "id": "fuETSHThCZG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_matrix(D,d): #this returns a sparse projection matrix. The other kinds of projection matrices will be defined later\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  non_zero_prob = 1/math.sqrt(D)\n",
        "  mat = mat/non_zero_prob\n",
        "  mat = torch.nn.functional.dropout(mat, p=(1-non_zero_prob)).to_sparse()\n",
        "  return mat"
      ],
      "metadata": {
        "id": "8gWMloYQCvQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In my neural networks I don't want to use regular layers. That is because\n",
        "#I don't want my layers to have trainable weights. There will be only\n",
        "#one trainable weight, which will be shared with the whole network.\n",
        "#So instead of using nn.Modules for my layers, I will use the functional API\n",
        "#of Pytorch. So, instead of layers, I will have functions with the same properties\n",
        "#asthe layers with the same name.\n",
        "#This is my linear layer, it has some weights that are not trainable.\n",
        "#When this function is called, it will be given as input its \"part\" of the shared weight\n",
        "class CustomLinear():\n",
        "  def __init__(self, size_in, size_out):\n",
        "    self.weight = torch.randn(size_out, size_in)\n",
        "    self.bias = torch.zeros(size_out)\n",
        "  def forward(self, x, theta_weight, theta_bias):\n",
        "    return F.linear(x, self.weight + theta_weight, bias = self.bias + theta_bias)"
      ],
      "metadata": {
        "id": "WYkM5oJUC5a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#and this is my convolutional layer\n",
        "class CustomConvolution():\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation = 1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None):\n",
        "    self.weight = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "    self.bias = torch.randn(out_channels)\n",
        "    self.padding = 0\n",
        "    self.stride = [1,1]\n",
        "  def forward(self, image, theta_weight, theta_bias):\n",
        "    return F.conv2d(image, self.weight + theta_weight, bias = self.bias+theta_bias, padding = \"same\")"
      ],
      "metadata": {
        "id": "uRqbeB9GEytS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearDenseModel(nn.Module): #this is a fully connected model,\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32):\n",
        "    self.d = d\n",
        "    #theta is the shared weight. It is initialized as 0. First i define all the layers of the network.\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, 1)\n",
        "\n",
        "    #then I precompute the dimension of the weights of the single layers. This will be useful when\n",
        "    #each layer will need as input its part of the shared weight\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * 1\n",
        "    last_layer_bias_D = 1\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d) #this is the projection matrix. Its type changes depending on the kind of network.\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "    #the first thing to do at each call, I need to compute the weights for the whole network, from my subset of trainable weights.\n",
        "    #each layer is given its part.\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (1, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "EdmX_QNWFRfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myDenseLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, first_dim = 1):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #this is the convolutional network. It works in the same way as the fully connected one.\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.first_dim = first_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))*first_dim\n",
        "\n",
        "    self.first_convolution = CustomConvolution(in_channels,6,5)\n",
        "    current_channels = 6\n",
        "    self.second_convolution = CustomConvolution(current_channels, out_channels, 5)\n",
        "\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        self.hidden_layers.append(CustomLinear(self.flatten_dim, hidden_dim))\n",
        "        continue\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, output_dim)\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_convolution.forward(x, first_convolution_theta_weight, first_convolution_theta_bias)\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = self.second_convolution.forward(y, second_convolution_theta_weight, second_convolution_theta_bias)\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "\n",
        "    y = torch.flatten(y)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    y = F.softmax(y, dim=0)\n",
        "    return y"
      ],
      "metadata": {
        "id": "kWfNne0VGuSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearSparseModel(nn.Module): #It's the same as the other Linear Model, but it has a sparse projection matrix\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32):\n",
        "    self.d = d\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, 1)\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * 1\n",
        "    last_layer_bias_D = 1\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = sparse_matrix(self.D, self.d)\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (1, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "2I77FTsuHLf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mySparseLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, first_dim = 1):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.first_dim = first_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))*first_dim\n",
        "\n",
        "    self.first_convolution = CustomConvolution(in_channels,6,5)\n",
        "    current_channels = 6\n",
        "    self.second_convolution = CustomConvolution(current_channels, out_channels, 5)\n",
        "\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        self.hidden_layers.append(CustomLinear(self.flatten_dim, hidden_dim))\n",
        "        continue\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, output_dim)\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "    self.projection = sparse_matrix(self.D, self.d)\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_convolution.forward(x, first_convolution_theta_weight, first_convolution_theta_bias)\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = self.second_convolution.forward(y, second_convolution_theta_weight, second_convolution_theta_bias)\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "\n",
        "    y = torch.flatten(y)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    y = F.softmax(y, dim=0)\n",
        "    return y"
      ],
      "metadata": {
        "id": "J8LGInjvl4c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random-Kitchen-Sinks"
      ],
      "metadata": {
        "id": "HUyHSXEgIOX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is everything for the various implementations of the random-kitchen-sinks. In addition to Fastfood, I tried with 2 more kinds of projection matrices"
      ],
      "metadata": {
        "id": "JzsQRVPQIRco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fastfood_matrices(dim):\n",
        "  B = torch.randn(dim) #diagonal of the matrices\n",
        "  B = B/torch.absolute(B)\n",
        "  pi = torch.randperm(dim) #instead of saving the matrix, I save the permutation it represents\n",
        "  G = torch.randn(dim)\n",
        "  return G, pi, B"
      ],
      "metadata": {
        "id": "rga-4in_IjXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_multiple_fastfood_matrices(dim, number): #this will generate the matrices needed for Fastfood.\n",
        "  Bs =[]\n",
        "  pis = []\n",
        "  Gs = []\n",
        "  for i in range(number):\n",
        "    B = torch.randn(dim)\n",
        "    B = B/torch.absolute(B)\n",
        "    Bs.append(B)\n",
        "    pi = torch.randperm(dim)\n",
        "    pis.append(pi)\n",
        "    G = torch.randn(dim)\n",
        "    Gs.append(G)\n",
        "    return Gs, pis, Bs"
      ],
      "metadata": {
        "id": "fHUUH0NAI3nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def permutation(vec, perm):\n",
        "  ret = torch.zeros_like(vec)\n",
        "  ret[perm] = vec\n",
        "  return ret"
      ],
      "metadata": {
        "id": "DT_coQx9JMsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I had to make 2 different versions of the Random-Kitchen-Sinks algorithms\n",
        "#One for checking the accuracy of the models, and one to check the speed\n",
        "#that is because my most optimal version speed-wise would not be able to track the gradients\n",
        "#here the problems are these functions from other libraries I am using\n",
        "def fastfood_calculation(x, G, pi, B):\n",
        "  length = len(x)\n",
        "  output = torch.Tensor(fwht(x)[0:length])\n",
        "  output = output * G\n",
        "  output = permutation(output,pi)\n",
        "  output = torch.Tensor(fwht(output)[0:length])\n",
        "  output = output * B\n",
        "  return output"
      ],
      "metadata": {
        "id": "riPHTgxMJR1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_fastfood_calculation(x, Gs, pis, Bs, D):\n",
        "  ret = torch.zeros(0)\n",
        "  for i in range(len(Gs)):\n",
        "\n",
        "    length = len(x)\n",
        "    output = torch.Tensor(fwht(x)[0:length])\n",
        "    output = output * Gs[i]\n",
        "    output = permutation(output,pis[i])\n",
        "    output = torch.Tensor(fwht(output)[0:length])\n",
        "    output = output * Bs[i]\n",
        "    ret = torch.cat((ret,output))\n",
        "  return ret[0:D]"
      ],
      "metadata": {
        "id": "Oe9YHv3VJbwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#an alternative to the Hadamard Matrix in Fastfood is the Discrete Cosine Transform.\n",
        "#This generates the projection matrix using DCT\n",
        "def full_cosine_calculation(x, Gs, pis, Bs, D):\n",
        "  ret = torch.zeros(0)\n",
        "  for i in range(len(Gs)):\n",
        "\n",
        "    length = len(x)\n",
        "    output = torch.Tensor(scipy.fft.dct(x.numpy(), norm = \"ortho\"))\n",
        "    output = output * Gs[i]\n",
        "    output = permutation(output,pis[i])\n",
        "    output = torch.Tensor(scipy.fft.dct(output.numpy(), norm = \"ortho\"))\n",
        "    output = output * Bs[i]\n",
        "    ret = torch.cat((ret,output))\n",
        "  return ret[0:D]"
      ],
      "metadata": {
        "id": "uANuj0ZJJdgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#another option for the Random-Kitchen-Sinks algorithm are Orthogonal Random Features\n",
        "#As are described here https://arxiv.org/pdf/1610.09072.pdf"
      ],
      "metadata": {
        "id": "fmy4O1iNJ38P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orthogonal_random_features(d):\n",
        "  Phi = np.random.randn(d, d).astype(np.float32)\n",
        "  Q = orth(Phi)[:d]"
      ],
      "metadata": {
        "id": "ijZsXSlfJzq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orthogonal_random_matrices(d):\n",
        "  Phi = np.random.randn(d, d).astype(np.float32)\n",
        "  Q = orth(Phi)[:d]\n",
        "  #compute S\n",
        "  S = torch.randn((d,d))\n",
        "  S = S ** 2\n",
        "  S = torch.sum(S,dim=0)\n",
        "  S = torch.sqrt(S)\n",
        "  S = torch.diag(S)\n",
        "  return Q,S"
      ],
      "metadata": {
        "id": "i2LXh2xzJzvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_orthogonal_random_matrices(d, number):\n",
        "  Qs = []\n",
        "  Ss = []\n",
        "  for i in range(number):\n",
        "    Phi = np.random.randn(d, d).astype(np.float32)\n",
        "    Q = orth(Phi)[:d]\n",
        "    #compute S\n",
        "    S = torch.randn((d,d))\n",
        "    S = S ** 2\n",
        "    S = torch.sum(S,dim=0)\n",
        "    S = torch.sqrt(S)\n",
        "    S = torch.diag(S)\n",
        "    Qs.append(Q)\n",
        "    Ss.append(S)\n",
        "  return Qs, Ss"
      ],
      "metadata": {
        "id": "DjzL8FfpKPPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_orthogonal_random_calculation(x, Qs, Ss, D):\n",
        "  result = torch.zeros(0)\n",
        "  for i in range(len(Qs)):\n",
        "    result = torch.cat((result,x@Qs[i]@Ss[i]))\n",
        "  return result"
      ],
      "metadata": {
        "id": "AnhTb_K9KRzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normally, put tensors on GPU, as the results on GPU are more important\n",
        "gs, pis, bis = generate_multiple_fastfood_matrices(1000,1000)\n",
        "t1 = time.time()\n",
        "full_fastfood_calculation(torch.randn(1000),gs,pis,bis,1000000)\n",
        "t2 = time.time()\n",
        "full_cosine_calculation(torch.randn(1000),gs,pis,bis,1000000)\n",
        "t3 = time.time()\n",
        "qs, ss = multiple_orthogonal_random_matrices(100, 100)\n",
        "full_orthogonal_random_calculation(torch.randn(100), qs,ss,10000)\n",
        "t4 = time.time()"
      ],
      "metadata": {
        "id": "M6XFcuqMKWBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "qFWoG0-tKi_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here is an example on how to train this network\n",
        "#It is not that different from any other network.\n",
        "#However it's important to give to the optimizer the right weight"
      ],
      "metadata": {
        "id": "13vfRIvGKlsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "kSvDOrqALMro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = myDenseLeNet(5, in_channels = 3, input_dimension = 32, first_dim=4, output_dim=4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD([net.theta], lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "eGcGPKSyLQ_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        labels = labels/10\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "2ksy2qsRLTY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement Learning"
      ],
      "metadata": {
        "id": "Nob_2YZrLXGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Two different Reinforcement Learning problems were experimented with\n",
        "#the first one is Inverted Pendulum.\n",
        "#I used this tutorial as reference https://pytorch.org/rl/tutorials/coding_ppo.html"
      ],
      "metadata": {
        "id": "_pxHnd6hLemn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchrl\n",
        "!pip3 install gym[mujoco]\n",
        "!pip3 install tqdm"
      ],
      "metadata": {
        "id": "HFTfHVIRL-0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torch import nn\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (\n",
        "    Compose,\n",
        "    DoubleToFloat,\n",
        "    ObservationNorm,\n",
        "    StepCounter,\n",
        "    TransformedEnv,\n",
        ")\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "jWMj4-1MMAqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\" #if not torch.has_cuda else \"cuda:0\"\n",
        "num_cells = 16  # number of cells in each layer i.e. output dim.\n",
        "lr = 3e-4\n",
        "max_grad_norm = 1.0\n",
        "d = 20\n",
        "#restart"
      ],
      "metadata": {
        "id": "lhEn_ynAMCy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_skip = 1\n",
        "frames_per_batch = 1000 // frame_skip\n",
        "# For a complete training, bring the number of frames up to 1M\n",
        "total_frames = 10_000 // frame_skip"
      ],
      "metadata": {
        "id": "P2x9u0EnMEss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCcFThN4MViL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_batch_size = 64  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
        "num_epochs = 10  # optimisation steps per batch of data collected\n",
        "clip_epsilon = (\n",
        "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
        ")\n",
        "gamma = 0.99\n",
        "lmbda = 0.95\n",
        "entropy_eps = 1e-4"
      ],
      "metadata": {
        "id": "IHthKYDGxC7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_env = GymEnv(\"InvertedDoublePendulum-v4\", device=device, frame_skip=frame_skip)"
      ],
      "metadata": {
        "id": "VVHIA_PmxFDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    Compose(\n",
        "        # normalize observations\n",
        "        ObservationNorm(in_keys=[\"observation\"]),\n",
        "        DoubleToFloat(\n",
        "            in_keys=[\"observation\"],\n",
        "        ),\n",
        "        StepCounter(),\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "sMOB0sDGxHwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)"
      ],
      "metadata": {
        "id": "KgLsv9tLxJ5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"normalization constant shape:\", env.transform[0].loc.shape)"
      ],
      "metadata": {
        "id": "ls5n7_lqxMK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observation_spec:\", env.observation_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"done_spec:\", env.done_spec)\n",
        "print(\"action_spec:\", env.action_spec)\n",
        "print(\"state_spec:\", env.state_spec)"
      ],
      "metadata": {
        "id": "-F3wPnolxOZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "id": "GYX97igqxQrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rollout = env.rollout(3)\n",
        "print(\"rollout of three steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
      ],
      "metadata": {
        "id": "wXVOzQv-xTJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_net = nn.Sequential(\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(2 * env.action_spec.shape[-1], device=device),\n",
        "    NormalParamExtractor(),\n",
        ")"
      ],
      "metadata": {
        "id": "RIGf5gHsxWAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_actor_linear(nn.Module):\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 2, hidden_dim = 256):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, 2* env.action_spec.shape[-1])\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * 2* env.action_spec.shape[-1]\n",
        "    last_layer_bias_D = 2* env.action_spec.shape[-1]\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.param_extractor = NormalParamExtractor()\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (2* env.action_spec.shape[-1], self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "\n",
        "    y = self.param_extractor(y)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "EpwcAtAvfOZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_net = my_actor_linear(11,d, hidden_dim = num_cells)\n",
        "my_actor_net = actor_net"
      ],
      "metadata": {
        "id": "NX2z8kW7bwXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_module = TensorDictModule(\n",
        "    actor_net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"]\n",
        ")"
      ],
      "metadata": {
        "id": "4mhldlw6xYU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_module = ProbabilisticActor(\n",
        "    module=policy_module,\n",
        "    spec=env.action_spec,\n",
        "    in_keys=[\"loc\", \"scale\"],\n",
        "    distribution_class=TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"min\": env.action_spec.space.minimum,\n",
        "        \"max\": env.action_spec.space.maximum,\n",
        "    },\n",
        "    return_log_prob=True,\n",
        "    # we'll need the log-prob for the numerator of the importance weights\n",
        ")"
      ],
      "metadata": {
        "id": "A11ooH-2xaqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "my_policy_module = TensorDictModule(\n",
        "    my_actor_net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"]\n",
        ")\n",
        "#might need to modify this"
      ],
      "metadata": {
        "id": "3EreuHosiEve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_actor_net._modules"
      ],
      "metadata": {
        "id": "0OlkqjptoHw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "my_policy_module = ProbabilisticActor(\n",
        "    module=my_policy_module,\n",
        "    spec=env.action_spec,\n",
        "    in_keys=[\"loc\", \"scale\"],\n",
        "    distribution_class=TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"min\": env.action_spec.space.minimum,\n",
        "        \"max\": env.action_spec.space.maximum,\n",
        "    },\n",
        "    return_log_prob=True,\n",
        "    # we'll need the log-prob for the numerator of the importance weights\n",
        ")"
      ],
      "metadata": {
        "id": "Xod0MEViiF7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_net = nn.Sequential(\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(1, device=device),\n",
        ")\n",
        "\n",
        "value_module = ValueOperator(\n",
        "    module=value_net,\n",
        "    in_keys=[\"observation\"],\n",
        ")"
      ],
      "metadata": {
        "id": "kGAt6ADBxc9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running policy:\", policy_module(env.reset()))\n",
        "print(\"Running value:\", value_module(env.reset()))"
      ],
      "metadata": {
        "id": "WAGAYDjPxfpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy_module,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "H8kZAqATxiiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########\n",
        "my_collector = SyncDataCollector(\n",
        "    env,\n",
        "    my_policy_module,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "tQmWTkAnpbbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(frames_per_batch),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        ")"
      ],
      "metadata": {
        "id": "KrWiKccgxkw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantage_module = GAE(\n",
        "    gamma=gamma, lmbda=lmbda, value_network=value_module, average_gae=True\n",
        ")\n",
        "\n",
        "loss_module = ClipPPOLoss(\n",
        "    actor=policy_module,\n",
        "    critic=value_module,\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_bonus=bool(entropy_eps),\n",
        "    entropy_coef=entropy_eps,\n",
        "    # these keys match by default but we set this for completeness\n",
        "    value_target_key=advantage_module.value_target_key,\n",
        "    critic_coef=1.0,\n",
        "    gamma=0.99,\n",
        "    loss_critic_type=\"smooth_l1\",\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optim, total_frames // frames_per_batch, 0.0\n",
        ")"
      ],
      "metadata": {
        "id": "yo5D8qZ0xnDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, policy_module)\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
        "\n",
        "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
        "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "d93N8sK0xseo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(logs[\"reward\"])\n",
        "plt.title(\"training rewards (average)\")\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(logs[\"step_count\"])\n",
        "plt.title(\"Max step count (training)\")\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(logs[\"eval reward (sum)\"])\n",
        "plt.title(\"Return (test)\")\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(logs[\"eval step_count\"])\n",
        "plt.title(\"Max step count (test)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "auU6-zYww6ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(my_collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, policy_module)\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
        "\n",
        "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
        "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "_WNTQBw1puUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cart Pole"
      ],
      "metadata": {
        "id": "fAwid8RtMgtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The other Reinforcement Learning Problem that was experimented with is Cart Pole\n",
        "#I used this tutorial as reference\n",
        "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ],
      "metadata": {
        "id": "ZmHJh64SMiBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6OPUKDjNKBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgLyEWxq4uhL",
        "outputId": "7484b563-b7a8-4c76-c683-5a5095710d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.1.0+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Installing collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.1.0\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.1.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373077 sha256=fe3cbc783eefedbe4c92af41f22a10a47e18546cc4df5aafaeba98b631e2d05e\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n",
            "Collecting tianshou\n",
            "  Downloading tianshou-0.5.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.29.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tianshou) (4.66.1)\n",
            "Requirement already satisfied: numpy>1.16.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (1.23.5)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.13.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.1.0+cu118)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.56.4)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (3.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tianshou) (23.2)\n",
            "Collecting pettingzoo>=1.22 (from tianshou)\n",
            "  Downloading pettingzoo-1.24.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m840.8/840.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (0.0.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (67.7.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (2.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->tianshou) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->tianshou) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (3.2.2)\n",
            "Installing collected packages: pettingzoo, tianshou\n",
            "Successfully installed pettingzoo-1.24.1 tianshou-0.5.1\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Collecting ale-py~=0.7.5 (from gym[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2 (from gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (6.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.66.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2023.7.22)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=0e2ab38a64b476f6175f145ce377109dd7cca18810318aae12d72b8d57ee8229\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: ale-py, AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.7.5 autorom-0.4.2\n",
            "/bin/bash: line 1: gym[accept-rom-license]: command not found\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.4.2)\n",
            "Collecting shimmy[atari]<1.0,>=0.1.0 (from gymnasium[accept-rom-license,atari])\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (4.66.1)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (0.6.1)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (6.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2023.7.22)\n",
            "Installing collected packages: ale-py, shimmy\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.7.5\n",
            "    Uninstalling ale-py-0.7.5:\n",
            "      Successfully uninstalled ale-py-0.7.5\n",
            "Successfully installed ale-py-0.8.1 shimmy-0.2.1\n",
            "Collecting envpool\n",
            "  Downloading envpool-0.8.3-cp310-cp310-manylinux_2_24_x86_64.whl (74.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m74.8/74.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-env>=1.4 (from envpool)\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gym>=0.18 in /usr/local/lib/python3.10/dist-packages (from envpool) (0.25.2)\n",
            "Requirement already satisfied: gymnasium>=0.26 in /usr/local/lib/python3.10/dist-packages (from envpool) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from envpool) (1.23.5)\n",
            "Collecting types-protobuf>=3.17.3 (from envpool)\n",
            "  Downloading types_protobuf-4.24.0.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from envpool) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from envpool) (23.2)\n",
            "Collecting optree>=0.6.0 (from envpool)\n",
            "  Downloading optree-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from dm-env>=1.4->envpool) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-env>=1.4->envpool) (0.1.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.18->envpool) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.18->envpool) (0.0.8)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26->envpool) (0.0.4)\n",
            "Installing collected packages: types-protobuf, optree, dm-env, envpool\n",
            "Successfully installed dm-env-1.6 envpool-0.8.3 optree-0.9.2 types-protobuf-4.24.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install stable_baselines3\n",
        "!pip install swig\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install tianshou\n",
        "!pip install \"gym[atari, accept-rom-license]\"\n",
        "!gym[accept-rom-license]\n",
        "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
        "!pip install envpool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip3 install gymnasium[classic_control]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svR1_jsd5JnH",
        "outputId": "c052d37e-7d90-48a1-8893-97ec3c71d14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[classic_control] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (2.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if GPU is to be used\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cpu\""
      ],
      "metadata": {
        "id": "0V2kveZW5X8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn_d = 1"
      ],
      "metadata": {
        "id": "Wa7gS2Cc_fEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_matrix (D,d):\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  return mat"
      ],
      "metadata": {
        "id": "OusHAzHCAB-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "WBYYtgWg5Z7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "yUdKtbqo7pHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear():\n",
        "  def __init__(self, size_in, size_out):\n",
        "    self.weight = torch.randn(size_out, size_in)\n",
        "    self.bias = torch.zeros(size_out)\n",
        "  def forward(self, x, theta_weight, theta_bias):\n",
        "    return F.linear(x, self.weight + theta_weight, bias = self.bias + theta_bias)\n",
        "    #return F.linear(x, self.weight, bias = self.bias)\n"
      ],
      "metadata": {
        "id": "7DnbA108-eFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, input_dimension, actions, d = dqn_d, n_hidden_layers = 2, hidden_dim = 128):\n",
        "    super(DQN,self).__init__()\n",
        "    self.d = d\n",
        "\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, n_actions)\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * n_actions\n",
        "    last_layer_bias_D = n_actions\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (n_actions, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "kW_tjw3k-BQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "rQ-hIaSp5cwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the ``AdamW`` optimizer\n",
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 1000\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state, info = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "#optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "optimizer = optim.AdamW([policy_net.theta], lr=LR, amsgrad=True)\n",
        "\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations(show_result=False):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ],
      "metadata": {
        "id": "uyNpCo2R5gi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_([policy_net.theta], 100)\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "iq3Tb30p5kBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    num_episodes = 600\n",
        "else:\n",
        "    num_episodes = 50\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    state, info = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    for t in count():\n",
        "        action = select_action(state)\n",
        "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        #     + (1  )\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            break\n",
        "\n",
        "print('Complete')\n",
        "plot_durations(show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "QSKXoMzM5nEd",
        "outputId": "67a56125-7069-4c03-fb18-934a0b05f5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}