{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Training on Parameter subspaces"
      ],
      "metadata": {
        "id": "OnSvbAz_CLMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "SrT0Svr-CP-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYrXvMRQwJEn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "from math import sqrt\n",
        "import time\n",
        "from sympy import fwht\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import scipy\n",
        "import numpy as np\n",
        "from scipy.linalg import orth\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions"
      ],
      "metadata": {
        "id": "n5EhMGynCToa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_matrix (D,d): #this returns a dense projection matrix\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  return mat"
      ],
      "metadata": {
        "id": "fuETSHThCZG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_matrix(D,d): #this returns a sparse projection matrix. The other kinds of projection matrices will be defined later\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  non_zero_prob = 1/math.sqrt(D)\n",
        "  mat = mat/non_zero_prob\n",
        "  mat = torch.nn.functional.dropout(mat, p=(1-non_zero_prob)).to_sparse()\n",
        "  return mat"
      ],
      "metadata": {
        "id": "8gWMloYQCvQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In my neural networks I don't want to use regular layers. That is because\n",
        "#I don't want my layers to have trainable weights. There will be only\n",
        "#one trainable weight, which will be shared with the whole network.\n",
        "#So instead of using nn.Modules for my layers, I will use the functional API\n",
        "#of Pytorch. So, instead of layers, I will have functions with the same properties\n",
        "#asthe layers with the same name.\n",
        "#This is my linear layer, it has some weights that are not trainable.\n",
        "#When this function is called, it will be given as input its \"part\" of the shared weight\n",
        "class CustomLinear():\n",
        "  def __init__(self, size_in, size_out):\n",
        "    self.weight = torch.randn(size_out, size_in)\n",
        "    self.bias = torch.zeros(size_out)\n",
        "  def forward(self, x, theta_weight, theta_bias):\n",
        "    return F.linear(x, self.weight + theta_weight, bias = self.bias + theta_bias)"
      ],
      "metadata": {
        "id": "WYkM5oJUC5a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#and this is my convolutional layer\n",
        "class CustomConvolution():\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation = 1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None):\n",
        "    self.weight = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "    self.bias = torch.randn(out_channels)\n",
        "    self.padding = 0\n",
        "    self.stride = [1,1]\n",
        "  def forward(self, image, theta_weight, theta_bias):\n",
        "    return F.conv2d(image, self.weight + theta_weight, bias = self.bias+theta_bias, padding = \"same\")"
      ],
      "metadata": {
        "id": "uRqbeB9GEytS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearDenseModel(nn.Module): #this is a fully connected model,\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32):\n",
        "    self.d = d\n",
        "    #theta is the shared weight. It is initialized as 0. First i define all the layers of the network.\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, 1)\n",
        "\n",
        "    #then I precompute the dimension of the weights of the single layers. This will be useful when\n",
        "    #each layer will need as input its part of the shared weight\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * 1\n",
        "    last_layer_bias_D = 1\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d) #this is the projection matrix. Its type changes depending on the kind of network.\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "    #the first thing to do at each call, I need to compute the weights for the whole network, from my subset of trainable weights.\n",
        "    #each layer is given its part.\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (1, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "EdmX_QNWFRfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myDenseLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, first_dim = 1):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #this is the convolutional network. It works in the same way as the fully connected one.\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.first_dim = first_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))*first_dim\n",
        "\n",
        "    self.first_convolution = CustomConvolution(in_channels,6,5)\n",
        "    current_channels = 6\n",
        "    self.second_convolution = CustomConvolution(current_channels, out_channels, 5)\n",
        "\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        self.hidden_layers.append(CustomLinear(self.flatten_dim, hidden_dim))\n",
        "        continue\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, output_dim)\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_convolution.forward(x, first_convolution_theta_weight, first_convolution_theta_bias)\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = self.second_convolution.forward(y, second_convolution_theta_weight, second_convolution_theta_bias)\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "\n",
        "    y = torch.flatten(y)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    y = F.softmax(y, dim=0)\n",
        "    return y"
      ],
      "metadata": {
        "id": "kWfNne0VGuSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearSparseModel(nn.Module): #It's the same as the other Linear Model, but it has a sparse projection matrix\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32):\n",
        "    self.d = d\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, 1)\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * 1\n",
        "    last_layer_bias_D = 1\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = sparse_matrix(self.D, self.d)\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (1, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "2I77FTsuHLf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mySparseLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, first_dim = 1):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.first_dim = first_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))*first_dim\n",
        "\n",
        "    self.first_convolution = CustomConvolution(in_channels,6,5)\n",
        "    current_channels = 6\n",
        "    self.second_convolution = CustomConvolution(current_channels, out_channels, 5)\n",
        "\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        self.hidden_layers.append(CustomLinear(self.flatten_dim, hidden_dim))\n",
        "        continue\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, output_dim)\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "    self.projection = sparse_matrix(self.D, self.d)\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_convolution.forward(x, first_convolution_theta_weight, first_convolution_theta_bias)\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = self.second_convolution.forward(y, second_convolution_theta_weight, second_convolution_theta_bias)\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "\n",
        "    y = torch.flatten(y)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "    y = F.softmax(y, dim=0)\n",
        "    return y"
      ],
      "metadata": {
        "id": "J8LGInjvl4c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random-Kitchen-Sinks"
      ],
      "metadata": {
        "id": "HUyHSXEgIOX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is everything for the various implementations of the random-kitchen-sinks. In addition to Fastfood, I tried with 2 more kinds of projection matrices"
      ],
      "metadata": {
        "id": "JzsQRVPQIRco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fastfood_matrices(dim):\n",
        "  B = torch.randn(dim) #diagonal of the matrices\n",
        "  B = B/torch.absolute(B)\n",
        "  pi = torch.randperm(dim) #instead of saving the matrix, I save the permutation it represents\n",
        "  G = torch.randn(dim)\n",
        "  return G, pi, B"
      ],
      "metadata": {
        "id": "rga-4in_IjXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_multiple_fastfood_matrices(dim, number): #this will generate the matrices needed for Fastfood.\n",
        "  Bs =[]\n",
        "  pis = []\n",
        "  Gs = []\n",
        "  for i in range(number):\n",
        "    B = torch.randn(dim)\n",
        "    B = B/torch.absolute(B)\n",
        "    Bs.append(B)\n",
        "    pi = torch.randperm(dim)\n",
        "    pis.append(pi)\n",
        "    G = torch.randn(dim)\n",
        "    Gs.append(G)\n",
        "    return Gs, pis, Bs"
      ],
      "metadata": {
        "id": "fHUUH0NAI3nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def permutation(vec, perm):\n",
        "  ret = torch.zeros_like(vec)\n",
        "  ret[perm] = vec\n",
        "  return ret"
      ],
      "metadata": {
        "id": "DT_coQx9JMsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I had to make 2 different versions of the Random-Kitchen-Sinks algorithms\n",
        "#One for checking the accuracy of the models, and one to check the speed\n",
        "#that is because my most optimal version speed-wise would not be able to track the gradients\n",
        "#here the problems are these functions from other libraries I am using\n",
        "def fastfood_calculation(x, G, pi, B):\n",
        "  length = len(x)\n",
        "  output = torch.Tensor(fwht(x)[0:length])\n",
        "  output = output * G\n",
        "  output = permutation(output,pi)\n",
        "  output = torch.Tensor(fwht(output)[0:length])\n",
        "  output = output * B\n",
        "  return output"
      ],
      "metadata": {
        "id": "riPHTgxMJR1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_fastfood_calculation(x, Gs, pis, Bs, D):\n",
        "  ret = torch.zeros(0)\n",
        "  for i in range(len(Gs)):\n",
        "\n",
        "    length = len(x)\n",
        "    output = torch.Tensor(fwht(x)[0:length])\n",
        "    output = output * Gs[i]\n",
        "    output = permutation(output,pis[i])\n",
        "    output = torch.Tensor(fwht(output)[0:length])\n",
        "    output = output * Bs[i]\n",
        "    ret = torch.cat((ret,output))\n",
        "  return ret[0:D]"
      ],
      "metadata": {
        "id": "Oe9YHv3VJbwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#an alternative to the Hadamard Matrix in Fastfood is the Discrete Cosine Transform.\n",
        "#This generates the projection matrix using DCT\n",
        "def full_cosine_calculation(x, Gs, pis, Bs, D):\n",
        "  ret = torch.zeros(0)\n",
        "  for i in range(len(Gs)):\n",
        "\n",
        "    length = len(x)\n",
        "    output = torch.Tensor(scipy.fft.dct(x.numpy(), norm = \"ortho\"))\n",
        "    output = output * Gs[i]\n",
        "    output = permutation(output,pis[i])\n",
        "    output = torch.Tensor(scipy.fft.dct(output.numpy(), norm = \"ortho\"))\n",
        "    output = output * Bs[i]\n",
        "    ret = torch.cat((ret,output))\n",
        "  return ret[0:D]"
      ],
      "metadata": {
        "id": "uANuj0ZJJdgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#another option for the Random-Kitchen-Sinks algorithm are Orthogonal Random Features\n",
        "#As are described here https://arxiv.org/pdf/1610.09072.pdf"
      ],
      "metadata": {
        "id": "fmy4O1iNJ38P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orthogonal_random_features(d):\n",
        "  Phi = np.random.randn(d, d).astype(np.float32)\n",
        "  Q = orth(Phi)[:d]"
      ],
      "metadata": {
        "id": "ijZsXSlfJzq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orthogonal_random_matrices(d):\n",
        "  Phi = np.random.randn(d, d).astype(np.float32)\n",
        "  Q = orth(Phi)[:d]\n",
        "  #compute S\n",
        "  S = torch.randn((d,d))\n",
        "  S = S ** 2\n",
        "  S = torch.sum(S,dim=0)\n",
        "  S = torch.sqrt(S)\n",
        "  S = torch.diag(S)\n",
        "  return Q,S"
      ],
      "metadata": {
        "id": "i2LXh2xzJzvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_orthogonal_random_matrices(d, number):\n",
        "  Qs = []\n",
        "  Ss = []\n",
        "  for i in range(number):\n",
        "    Phi = np.random.randn(d, d).astype(np.float32)\n",
        "    Q = orth(Phi)[:d]\n",
        "    #compute S\n",
        "    S = torch.randn((d,d))\n",
        "    S = S ** 2\n",
        "    S = torch.sum(S,dim=0)\n",
        "    S = torch.sqrt(S)\n",
        "    S = torch.diag(S)\n",
        "    Qs.append(Q)\n",
        "    Ss.append(S)\n",
        "  return Qs, Ss"
      ],
      "metadata": {
        "id": "DjzL8FfpKPPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_orthogonal_random_calculation(x, Qs, Ss, D):\n",
        "  result = torch.zeros(0)\n",
        "  for i in range(len(Qs)):\n",
        "    result = torch.cat((result,x@Qs[i]@Ss[i]))\n",
        "  return result"
      ],
      "metadata": {
        "id": "AnhTb_K9KRzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normally, put tensors on GPU, as the results on GPU are more important\n",
        "gs, pis, bis = generate_multiple_fastfood_matrices(1000,1000)\n",
        "t1 = time.time()\n",
        "full_fastfood_calculation(torch.randn(1000),gs,pis,bis,1000000)\n",
        "t2 = time.time()\n",
        "full_cosine_calculation(torch.randn(1000),gs,pis,bis,1000000)\n",
        "t3 = time.time()\n",
        "qs, ss = multiple_orthogonal_random_matrices(100, 100)\n",
        "#full_orthogonal_random_calculation(torch.randn(100), qs,ss,10000)\n",
        "#t4 = time.time()"
      ],
      "metadata": {
        "id": "M6XFcuqMKWBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "qFWoG0-tKi_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#here is an example on how to train this network\n",
        "#It is not that different from any other network.\n",
        "#However it's important to give to the optimizer the right weight"
      ],
      "metadata": {
        "id": "13vfRIvGKlsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "kSvDOrqALMro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = myDenseLeNet(5, in_channels = 3, input_dimension = 32, first_dim=4, output_dim=4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD([net.theta], lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "eGcGPKSyLQ_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        labels = labels/10\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "2ksy2qsRLTY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement Learning"
      ],
      "metadata": {
        "id": "Nob_2YZrLXGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Two different Reinforcement Learning problems were experimented with\n",
        "#the first one is Inverted Pendulum.\n",
        "#I used this tutorial as reference https://pytorch.org/rl/tutorials/coding_ppo.html"
      ],
      "metadata": {
        "id": "_pxHnd6hLemn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchrl\n",
        "!pip3 install gym[mujoco]\n",
        "!pip3 install tqdm"
      ],
      "metadata": {
        "id": "HFTfHVIRL-0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torch import nn\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (\n",
        "    Compose,\n",
        "    DoubleToFloat,\n",
        "    ObservationNorm,\n",
        "    StepCounter,\n",
        "    TransformedEnv,\n",
        ")\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "jWMj4-1MMAqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\" #if not torch.has_cuda else \"cuda:0\"\n",
        "num_cells = 16  # number of cells in each layer i.e. output dim.\n",
        "lr = 3e-4\n",
        "max_grad_norm = 1.0\n",
        "d = 20\n",
        "#restart"
      ],
      "metadata": {
        "id": "lhEn_ynAMCy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_skip = 1\n",
        "frames_per_batch = 1000 // frame_skip\n",
        "# For a complete training, bring the number of frames up to 1M\n",
        "total_frames = 10_000 // frame_skip"
      ],
      "metadata": {
        "id": "P2x9u0EnMEss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCcFThN4MViL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_batch_size = 64  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
        "num_epochs = 10  # optimisation steps per batch of data collected\n",
        "clip_epsilon = (\n",
        "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
        ")\n",
        "gamma = 0.99\n",
        "lmbda = 0.95\n",
        "entropy_eps = 1e-4"
      ],
      "metadata": {
        "id": "IHthKYDGxC7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_env = GymEnv(\"InvertedDoublePendulum-v4\", device=device, frame_skip=frame_skip)"
      ],
      "metadata": {
        "id": "VVHIA_PmxFDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    Compose(\n",
        "        # normalize observations\n",
        "        ObservationNorm(in_keys=[\"observation\"]),\n",
        "        DoubleToFloat(\n",
        "            in_keys=[\"observation\"],\n",
        "        ),\n",
        "        StepCounter(),\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "sMOB0sDGxHwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)"
      ],
      "metadata": {
        "id": "KgLsv9tLxJ5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"normalization constant shape:\", env.transform[0].loc.shape)"
      ],
      "metadata": {
        "id": "ls5n7_lqxMK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observation_spec:\", env.observation_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"done_spec:\", env.done_spec)\n",
        "print(\"action_spec:\", env.action_spec)\n",
        "print(\"state_spec:\", env.state_spec)"
      ],
      "metadata": {
        "id": "-F3wPnolxOZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "id": "GYX97igqxQrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rollout = env.rollout(3)\n",
        "print(\"rollout of three steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
      ],
      "metadata": {
        "id": "wXVOzQv-xTJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_net = nn.Sequential(\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(2 * env.action_spec.shape[-1], device=device),\n",
        "    NormalParamExtractor(),\n",
        ")"
      ],
      "metadata": {
        "id": "RIGf5gHsxWAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_actor_linear(nn.Module):\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 2, hidden_dim = 256):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, 2* env.action_spec.shape[-1])\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * 2* env.action_spec.shape[-1]\n",
        "    last_layer_bias_D = 2* env.action_spec.shape[-1]\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.param_extractor = NormalParamExtractor()\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (2* env.action_spec.shape[-1], self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "\n",
        "    y = self.param_extractor(y)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "EpwcAtAvfOZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_net = my_actor_linear(11,d, hidden_dim = num_cells)\n",
        "my_actor_net = actor_net"
      ],
      "metadata": {
        "id": "NX2z8kW7bwXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_module = TensorDictModule(\n",
        "    actor_net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"]\n",
        ")"
      ],
      "metadata": {
        "id": "4mhldlw6xYU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_module = ProbabilisticActor(\n",
        "    module=policy_module,\n",
        "    spec=env.action_spec,\n",
        "    in_keys=[\"loc\", \"scale\"],\n",
        "    distribution_class=TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"min\": env.action_spec.space.minimum,\n",
        "        \"max\": env.action_spec.space.maximum,\n",
        "    },\n",
        "    return_log_prob=True,\n",
        "    # we'll need the log-prob for the numerator of the importance weights\n",
        ")"
      ],
      "metadata": {
        "id": "A11ooH-2xaqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "my_policy_module = TensorDictModule(\n",
        "    my_actor_net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"]\n",
        ")\n",
        "#might need to modify this"
      ],
      "metadata": {
        "id": "3EreuHosiEve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_actor_net._modules"
      ],
      "metadata": {
        "id": "0OlkqjptoHw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "my_policy_module = ProbabilisticActor(\n",
        "    module=my_policy_module,\n",
        "    spec=env.action_spec,\n",
        "    in_keys=[\"loc\", \"scale\"],\n",
        "    distribution_class=TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"min\": env.action_spec.space.minimum,\n",
        "        \"max\": env.action_spec.space.maximum,\n",
        "    },\n",
        "    return_log_prob=True,\n",
        "    # we'll need the log-prob for the numerator of the importance weights\n",
        ")"
      ],
      "metadata": {
        "id": "Xod0MEViiF7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_net = nn.Sequential(\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(1, device=device),\n",
        ")\n",
        "\n",
        "value_module = ValueOperator(\n",
        "    module=value_net,\n",
        "    in_keys=[\"observation\"],\n",
        ")"
      ],
      "metadata": {
        "id": "kGAt6ADBxc9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running policy:\", policy_module(env.reset()))\n",
        "print(\"Running value:\", value_module(env.reset()))"
      ],
      "metadata": {
        "id": "WAGAYDjPxfpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy_module,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "H8kZAqATxiiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########\n",
        "my_collector = SyncDataCollector(\n",
        "    env,\n",
        "    my_policy_module,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "tQmWTkAnpbbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(frames_per_batch),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        ")"
      ],
      "metadata": {
        "id": "KrWiKccgxkw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantage_module = GAE(\n",
        "    gamma=gamma, lmbda=lmbda, value_network=value_module, average_gae=True\n",
        ")\n",
        "\n",
        "loss_module = ClipPPOLoss(\n",
        "    actor=policy_module,\n",
        "    critic=value_module,\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_bonus=bool(entropy_eps),\n",
        "    entropy_coef=entropy_eps,\n",
        "    # these keys match by default but we set this for completeness\n",
        "    value_target_key=advantage_module.value_target_key,\n",
        "    critic_coef=1.0,\n",
        "    gamma=0.99,\n",
        "    loss_critic_type=\"smooth_l1\",\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optim, total_frames // frames_per_batch, 0.0\n",
        ")"
      ],
      "metadata": {
        "id": "yo5D8qZ0xnDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, policy_module)\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
        "\n",
        "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
        "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "d93N8sK0xseo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(logs[\"reward\"])\n",
        "plt.title(\"training rewards (average)\")\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(logs[\"step_count\"])\n",
        "plt.title(\"Max step count (training)\")\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(logs[\"eval reward (sum)\"])\n",
        "plt.title(\"Return (test)\")\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(logs[\"eval step_count\"])\n",
        "plt.title(\"Max step count (test)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "auU6-zYww6ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(my_collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, policy_module)\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
        "\n",
        "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
        "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "_WNTQBw1puUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cart Pole"
      ],
      "metadata": {
        "id": "fAwid8RtMgtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The other Reinforcement Learning Problem that was experimented with is Cart Pole\n",
        "#I used this tutorial as reference\n",
        "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ],
      "metadata": {
        "id": "ZmHJh64SMiBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6OPUKDjNKBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgLyEWxq4uhL"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium\n",
        "!pip install stable_baselines3\n",
        "!pip install swig\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install tianshou\n",
        "!pip install \"gym[atari, accept-rom-license]\"\n",
        "!gym[accept-rom-license]\n",
        "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
        "!pip install envpool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip3 install gymnasium[classic_control]"
      ],
      "metadata": {
        "id": "svR1_jsd5JnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if GPU is to be used\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cpu\""
      ],
      "metadata": {
        "id": "0V2kveZW5X8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn_d = 1"
      ],
      "metadata": {
        "id": "Wa7gS2Cc_fEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_matrix (D,d):\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  return mat"
      ],
      "metadata": {
        "id": "OusHAzHCAB-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "WBYYtgWg5Z7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "yUdKtbqo7pHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear():\n",
        "  def __init__(self, size_in, size_out):\n",
        "    self.weight = torch.randn(size_out, size_in)\n",
        "    self.bias = torch.zeros(size_out)\n",
        "  def forward(self, x, theta_weight, theta_bias):\n",
        "    return F.linear(x, self.weight + theta_weight, bias = self.bias + theta_bias)\n",
        "    #return F.linear(x, self.weight, bias = self.bias)\n"
      ],
      "metadata": {
        "id": "7DnbA108-eFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, input_dimension, actions, d = dqn_d, n_hidden_layers = 2, hidden_dim = 128):\n",
        "    super(DQN,self).__init__()\n",
        "    self.d = d\n",
        "\n",
        "    self.theta = torch.zeros(d, requires_grad = True)\n",
        "    self.first_layer = CustomLinear(input_dimension, hidden_dim)\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.hidden_layers = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      self.hidden_layers.append(CustomLinear(hidden_dim, hidden_dim))\n",
        "    self.last_layer = CustomLinear(hidden_dim, n_actions)\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * n_actions\n",
        "    last_layer_bias_D = n_actions\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (n_actions, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = self.first_layer.forward(x, first_layer_theta_weight, first_layer_theta_bias)\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = self.hidden_layers[i].forward(y,hidden_layers_theta_weight[i], hidden_layers_theta_bias[i])\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = self.last_layer.forward(y, last_layer_theta_weight, last_layer_theta_bias)\n",
        "\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "kW_tjw3k-BQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "rQ-hIaSp5cwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the ``AdamW`` optimizer\n",
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 1000\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state, info = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "#optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "optimizer = optim.AdamW([policy_net.theta], lr=LR, amsgrad=True)\n",
        "\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations(show_result=False):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ],
      "metadata": {
        "id": "uyNpCo2R5gi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_([policy_net.theta], 100)\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "iq3Tb30p5kBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    num_episodes = 600\n",
        "else:\n",
        "    num_episodes = 50\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    state, info = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    for t in count():\n",
        "        action = select_action(state)\n",
        "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        # θ′ ← τ θ + (1 −τ )θ′\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            break\n",
        "\n",
        "print('Complete')\n",
        "plot_durations(show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QSKXoMzM5nEd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}