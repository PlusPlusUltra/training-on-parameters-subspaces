{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akkVwdM7rUVn"
      },
      "source": [
        "Training on Parameter subspaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpDQvf9_rUVo"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BkzKP3NZrUVo"
      },
      "outputs": [],
      "source": [
        "!pip install -q hadamard-transform\n",
        "!pip install -q torch-dct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xYrXvMRQwJEn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "from math import sqrt\n",
        "import time\n",
        "from sympy import fwht\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import scipy\n",
        "import numpy as np\n",
        "from scipy.linalg import orth\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from hadamard_transform import hadamard_transform, pad_to_power_of_2\n",
        "import torch_dct as dct\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8G2rWIyxiLH3"
      },
      "outputs": [],
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5EhMGynCToa"
      },
      "source": [
        "Defining functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fuETSHThCZG6"
      },
      "outputs": [],
      "source": [
        "def dense_matrix (D,d): #this returns a dense projection matrix\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  return mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8gWMloYQCvQo"
      },
      "outputs": [],
      "source": [
        "def sparse_matrix(D,d): #this returns a sparse projection matrix. The other kinds of projection matrices will be defined later\n",
        "  mat = torch.rand(D,d)\n",
        "  mat = torch.nn.functional.normalize(mat, p=2.0, dim = 0)\n",
        "  non_zero_prob = 1/math.sqrt(D)\n",
        "  mat = mat/non_zero_prob\n",
        "  mat = torch.nn.functional.dropout(mat, p=(1-non_zero_prob)).to_sparse()\n",
        "  return mat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearDenseModel(nn.Module): #this is a fully connected model,\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32, output_dim = 1, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #theta is the shared weight. It is initialized as 0. First i define all the layers of the network.\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    #then I precompute the dimension of the weights of the single layers. This will be useful when\n",
        "    #each layer will need as input its part of the shared weight\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d) #this is the projection matrix. Its type changes depending on the kind of network.\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.projection = self.projection.to(device)\n",
        "    ####\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    #the first thing to do at each call, I need to compute the weights for the whole network, from my subset of trainable weights.\n",
        "    #each layer is given its part.\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.linear(x, first_layer_theta_weight/math.sqrt(first_layer_theta_weight.shape[1]), first_layer_theta_bias/math.sqrt(first_layer_theta_weight.shape[1]))\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "prQl3H0rrOYf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myDenseLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #this is the convolutional network. It works in the same way as the fully connected one.\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.projection = self.projection.to(dev)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.conv2d(x, first_convolution_theta_weight/math.sqrt(first_convolution_theta_weight.shape[1]*25), first_convolution_theta_bias/math.sqrt(first_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = F.conv2d(y, second_convolution_theta_weight/math.sqrt(second_convolution_theta_weight.shape[1]*25), second_convolution_theta_bias/math.sqrt(second_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = torch.flatten(y, start_dim = -3)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y"
      ],
      "metadata": {
        "id": "ITbBhjRTsB6I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearSparseModel(nn.Module):\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32, output_dim = 1, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #theta is the shared weight. It is initialized as 0. First i define all the layers of the network.\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    #then I precompute the dimension of the weights of the single layers. This will be useful when\n",
        "    #each layer will need as input its part of the shared weight\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = sparse_matrix(self.D, self.d) #this is the projection matrix. Its type changes depending on the kind of network.\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.projection, self.theta = self.projection.to(device), self.theta.to(device)\n",
        "    ####\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    #the first thing to do at each call, I need to compute the weights for the whole network, from my subset of trainable weights.\n",
        "    #each layer is given its part.\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.linear(x, first_layer_theta_weight/math.sqrt(first_layer_theta_weight.shape[1]), first_layer_theta_bias/math.sqrt(first_layer_theta_weight.shape[1]))\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "s3eREbk-sdU3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mySparseLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #this is the convolutional network. It works in the same way as the fully connected one.\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "    self.projection = sparse_matrix(self.D, self.d)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.projection = self.projection.to(dev)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.conv2d(x, first_convolution_theta_weight/math.sqrt(first_convolution_theta_weight.shape[1]*25), first_convolution_theta_bias/math.sqrt(first_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = F.conv2d(y, second_convolution_theta_weight/math.sqrt(second_convolution_theta_weight.shape[1]*25), second_convolution_theta_bias/math.sqrt(second_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = torch.flatten(y, start_dim = -3)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y"
      ],
      "metadata": {
        "id": "H6fhNP9rtFeZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUyHSXEgIOX_"
      },
      "source": [
        "Random-Kitchen-Sinks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzsQRVPQIRco"
      },
      "source": [
        "Here is everything for the various implementations of the random-kitchen-sinks. In addition to Fastfood, I tried with 2 more kinds of projection matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rga-4in_IjXO"
      },
      "outputs": [],
      "source": [
        "def generate_fastfood_matrices(dim):\n",
        "  B = torch.randn(dim) #diagonal of the matrices\n",
        "  B = B/torch.absolute(B)\n",
        "  pi = torch.randperm(dim) #instead of saving the matrix, I save the permutation it represents\n",
        "  G = torch.randn(dim)\n",
        "  return G, pi, B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fHUUH0NAI3nd"
      },
      "outputs": [],
      "source": [
        "def generate_multiple_fastfood_matrices(dim, number): #this will generate the matrices needed for Fastfood.\n",
        "  Bs =[]\n",
        "  pis = []\n",
        "  Gs = []\n",
        "  for i in range(number):\n",
        "    B = torch.randn(dim)\n",
        "    B = B/torch.absolute(B)\n",
        "    Bs.append(B)\n",
        "    pi = torch.randperm(dim)\n",
        "    pis.append(pi)\n",
        "    G = torch.randn(dim)\n",
        "    Gs.append(G)\n",
        "    return Gs, pis, Bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DT_coQx9JMsN"
      },
      "outputs": [],
      "source": [
        "def permutation(vec, perm):\n",
        "  ret = torch.zeros_like(vec)\n",
        "  ret[perm] = vec\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "riPHTgxMJR1E"
      },
      "outputs": [],
      "source": [
        "#I had to make 2 different versions of the Random-Kitchen-Sinks algorithms\n",
        "#One for checking the accuracy of the models, and one to check the speed\n",
        "#that is because my most optimal version speed-wise would not be able to track the gradients\n",
        "#here the problems are these functions from other libraries I am using\n",
        "def fastfood_calculation(x, G, pi, B):\n",
        "  length = len(x)\n",
        "  output = torch.Tensor(fwht(x)[0:length])\n",
        "  output = output * G\n",
        "  output = permutation(output,pi)\n",
        "  output = torch.Tensor(fwht(output)[0:length])\n",
        "  output = output * B\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Oe9YHv3VJbwo"
      },
      "outputs": [],
      "source": [
        "def full_fastfood_calculation(x, Gs, pis, Bs, D):\n",
        "  ret = torch.zeros(0)\n",
        "  for i in range(len(Gs)):\n",
        "\n",
        "    length = len(x)\n",
        "    output = torch.Tensor(fwht(x)[0:length])\n",
        "    output = output * Gs[i]\n",
        "    output = permutation(output,pis[i])\n",
        "    output = torch.Tensor(fwht(output)[0:length])\n",
        "    output = output * Bs[i]\n",
        "    ret = torch.cat((ret,output))\n",
        "  return ret[0:D]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uANuj0ZJJdgQ"
      },
      "outputs": [],
      "source": [
        "#an alternative to the Hadamard Matrix in Fastfood is the Discrete Cosine Transform.\n",
        "#This generates the projection matrix using DCT\n",
        "def full_cosine_calculation(x, Gs, pis, Bs, D):\n",
        "  ret = torch.zeros(0)\n",
        "  for i in range(len(Gs)):\n",
        "\n",
        "    length = len(x)\n",
        "    output = torch.Tensor(scipy.fft.dct(x.numpy(), norm = \"ortho\"))\n",
        "    output = output * Gs[i]\n",
        "    output = permutation(output,pis[i])\n",
        "    output = torch.Tensor(scipy.fft.dct(output.numpy(), norm = \"ortho\"))\n",
        "    output = output * Bs[i]\n",
        "    ret = torch.cat((ret,output))\n",
        "  return ret[0:D]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fmy4O1iNJ38P"
      },
      "outputs": [],
      "source": [
        "#another option for the Random-Kitchen-Sinks algorithm are Orthogonal Random Features\n",
        "#As are described here https://arxiv.org/pdf/1610.09072.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ijZsXSlfJzq5"
      },
      "outputs": [],
      "source": [
        "def orthogonal_random_features(d):\n",
        "  Phi = np.random.randn(d, d).astype(np.float32)\n",
        "  Q = orth(Phi)[:d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "i2LXh2xzJzvU"
      },
      "outputs": [],
      "source": [
        "def orthogonal_random_matrices(d):\n",
        "  Phi = np.random.randn(d, d).astype(np.float32)\n",
        "  Q = orth(Phi)[:d]\n",
        "  #compute S\n",
        "  S = torch.randn((d,d))\n",
        "  S = S ** 2\n",
        "  S = torch.sum(S,dim=0)\n",
        "  S = torch.sqrt(S)\n",
        "  S = torch.diag(S)\n",
        "  return Q,S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DjzL8FfpKPPt"
      },
      "outputs": [],
      "source": [
        "def multiple_orthogonal_random_matrices(d, number):\n",
        "  Qs = []\n",
        "  Ss = []\n",
        "  for i in range(number):\n",
        "    Phi = np.random.randn(d, d).astype(np.float32)\n",
        "    Q = orth(Phi)[:d]\n",
        "    #compute S\n",
        "    S = torch.randn((d,d))\n",
        "    S = S ** 2\n",
        "    S = torch.sum(S,dim=0)\n",
        "    S = torch.sqrt(S)\n",
        "    S = torch.diag(S)\n",
        "    Qs.append(Q)\n",
        "    Ss.append(S)\n",
        "  return Qs, Ss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AnhTb_K9KRzJ"
      },
      "outputs": [],
      "source": [
        "def full_orthogonal_random_calculation(x, Qs, Ss, D):\n",
        "  result = torch.zeros(0)\n",
        "  for i in range(len(Qs)):\n",
        "    result = torch.cat((result,x@Qs[i]@Ss[i]))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RgG6sT7buEF_"
      },
      "outputs": [],
      "source": [
        "def optimal_generate_fastfood_matrices(dim, number):\n",
        "  G = torch.randn(number, dim)\n",
        "  pi = torch.argsort(torch.rand(number, dim), dim=-1)\n",
        "  B = torch.randn(number, dim)\n",
        "  B = B/torch.absolute(B)\n",
        "  return G, pi, B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cgpiWvxJxPv9"
      },
      "outputs": [],
      "source": [
        "def optimal_fastfood_calculation(x, G, pi, B):\n",
        "  x = x.repeat(G.shape[0], 1)\n",
        "  after_H1 = hadamard_transform(pad_to_power_of_2(x))[:,:x.shape[1]]\n",
        "  after_G = after_H1*G\n",
        "  after_pi = after_G[torch.arange(after_G.shape[0]).unsqueeze(-1), pi]\n",
        "  after_H2 = hadamard_transform(pad_to_power_of_2(after_pi))[:,:after_pi.shape[1]]\n",
        "  after_B = after_H2 * B\n",
        "  return torch.flatten(after_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IWsskAO07pJN"
      },
      "outputs": [],
      "source": [
        "def optimal_cosine_calculation(x, G, pi, B):\n",
        "  x = x.repeat(G.shape[0], 1)\n",
        "  after_H1 = dct.dct(x)\n",
        "  after_G = after_H1*G\n",
        "  after_pi = after_G[torch.arange(after_G.shape[0]).unsqueeze(-1), pi]\n",
        "  after_H2 = dct.dct(after_pi)\n",
        "  after_B = after_H2 * B\n",
        "  return torch.flatten(after_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZUlWDtUe55OP"
      },
      "outputs": [],
      "source": [
        "def optimal_structured_orthogonal_random_matrices(dim, number):\n",
        "  D1 = torch.randn(number, dim)\n",
        "  D1 = D1/torch.absolute(D1)\n",
        "  D2 = torch.randn(number, dim)\n",
        "  D2 = D2/torch.absolute(D2)\n",
        "  D3 = torch.randn(number, dim)\n",
        "  D3 = D3/torch.absolute(D3)\n",
        "  return D1, D2, D3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5AcuPg2Q71vp"
      },
      "outputs": [],
      "source": [
        "def optimal_structured_orthogonal_random_calculation(x,D1,D2,D3):\n",
        "  x = x.repeat(D1.shape[0], 1)\n",
        "  y = hadamard_transform(pad_to_power_of_2(x))[:,:x.shape[1]]\n",
        "  y = y*D1\n",
        "  y = hadamard_transform(pad_to_power_of_2(y))[:,:y.shape[1]]\n",
        "  y = y*D2\n",
        "  y = hadamard_transform(pad_to_power_of_2(y))[:,:y.shape[1]]\n",
        "  y = y*D3\n",
        "  return torch.flatten(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "sSfnDdVRFsuQ"
      },
      "outputs": [],
      "source": [
        "T1 = torch.randn(100)\n",
        "T1 = T1.to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "wuwypCFZB5L4"
      },
      "outputs": [],
      "source": [
        "G, pi, B = optimal_generate_fastfood_matrices(100, 10000)\n",
        "qs, ss = multiple_orthogonal_random_matrices(100, 100)\n",
        "D1, D2, D3 = optimal_structured_orthogonal_random_matrices(100, 10000)\n",
        "G = G.to(dev)\n",
        "pi = pi.to(dev)\n",
        "B = B.to(dev)\n",
        "D1 = D1.to(dev)\n",
        "D2 = D2.to(dev)\n",
        "D3 = D3.to(dev)\n",
        "t1 = time.time()\n",
        "for i in range(100):\n",
        "  fastfood = optimal_fastfood_calculation(T1, G, pi, B)\n",
        "t2 = time.time()\n",
        "for i in range(100):\n",
        "\n",
        "  cosine = optimal_cosine_calculation(T1,G, pi, B)\n",
        "t3 = time.time()\n",
        "#full_orthogonal_random_calculation(torch.randn(100), qs,ss,10000)\n",
        "#t4 = time.time()\n",
        "for i in range(100):\n",
        "  orthogonal = optimal_structured_orthogonal_random_calculation(T1, D1, D2, D3)\n",
        "t5 = time.time()\n",
        "dense = dense_matrix(1000000, 100)#with d = 1000 the matrix would not fit into memory\n",
        "dense = dense.to(dev)\n",
        "sparse = sparse_matrix(1000000, 100)\n",
        "sparse = sparse.to(dev)\n",
        "\n",
        "t6 = time.time()\n",
        "for i in range(100):\n",
        "\n",
        "  dense_m = dense@T1\n",
        "t7 = time.time()\n",
        "for i in range(100):\n",
        "\n",
        "  sparse_m = sparse@T1\n",
        "t8 = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT8ZEmLdC59n",
        "outputId": "b12e4c1a-2842-442b-cd8c-6d44742dbae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4275338649749756\n",
            "0.3192417621612549\n",
            "0.30924296379089355\n"
          ]
        }
      ],
      "source": [
        "print(t2-t1)#with d = 1000 the times were 0.105, 0.036, 0.009(this doesn't count), 0.134\n",
        "print(t3-t2)\n",
        "#print(t4-t3)\n",
        "print(t5-t3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t7-t6)\n",
        "print(t8-t7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_ok9_PavEIt",
        "outputId": "6100eb00-c2e8-42fb-f265-8a11e92ba574"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.002134561538696289\n",
            "0.25193333625793457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnCMQtxLfK4"
      },
      "source": [
        "Random-Kitchen-Sinks layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hDJPzfOVIc-d"
      },
      "outputs": [],
      "source": [
        "class myLinearTransformModel(nn.Module): #this is a fully connected model,\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32, output_dim = 1, device = \"cpu\", transform = \"fastfood\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #theta is the shared weight. It is initialized as 0. First i define all the layers of the network.\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.output_dim = output_dim\n",
        "    #\n",
        "    self.transform = transform\n",
        "\n",
        "    #then I precompute the dimension of the weights of the single layers. This will be useful when\n",
        "    #each layer will need as input its part of the shared weight\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    #####\n",
        "    if self.transform == \"fastfood\":\n",
        "      self.transform_func = optimal_fastfood_calculation\n",
        "    else:\n",
        "      self.transform_func = optimal_cosine_calculation\n",
        "\n",
        "    G, pi, B = optimal_generate_fastfood_matrices(self.d, int(self.D/self.d + 1))\n",
        "    G = G[:self.D]\n",
        "    pi = pi[:self.D]\n",
        "    B = B[:self.D]\n",
        "    self.G = G.to(device)\n",
        "    self.pi = pi.to(device)\n",
        "    self.B = B.to(device)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.transform_func(self.theta, self.G, self.pi, self.B)\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    #the first thing to do at each call, I need to compute the weights for the whole network, from my subset of trainable weights.\n",
        "    #each layer is given its part.\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.linear(x, first_layer_theta_weight/math.sqrt(first_layer_theta_weight.shape[1]), first_layer_theta_bias/math.sqrt(first_layer_theta_weight.shape[1]))\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myTransformLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, device = \"cpu\", transform = \"fastfood\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))\n",
        "    self.transform = transform\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    ####\n",
        "    if self.transform == \"fastfood\":\n",
        "      self.transform_func = optimal_fastfood_calculation\n",
        "    else:\n",
        "      self.transform_func = optimal_cosine_calculation\n",
        "\n",
        "    G, pi, B = optimal_generate_fastfood_matrices(self.d, int(self.D/self.d + 1))\n",
        "    G = G[:self.D]\n",
        "    pi = pi[:self.D]\n",
        "    B = B[:self.D]\n",
        "    self.G = G.to(device)\n",
        "    self.pi = pi.to(device)\n",
        "    self.B = B.to(device)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.transform_func(self.theta, self.G, self.pi, self.B)\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.conv2d(x, first_convolution_theta_weight/math.sqrt(first_convolution_theta_weight.shape[1]*25), first_convolution_theta_bias/math.sqrt(first_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = F.conv2d(y, second_convolution_theta_weight/math.sqrt(second_convolution_theta_weight.shape[1]*25), second_convolution_theta_bias/math.sqrt(second_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = torch.flatten(y, start_dim = -3)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y"
      ],
      "metadata": {
        "id": "u-C-cjmm2Q5g"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myLinearRandomFeaturesModel(nn.Module): #this is a fully connected model,\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 4, hidden_dim = 32, output_dim = 1, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    #theta is the shared weight. It is initialized as 0. First i define all the layers of the network.\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.output_dim = output_dim\n",
        "    #\n",
        "\n",
        "    #then I precompute the dimension of the weights of the single layers. This will be useful when\n",
        "    #each layer will need as input its part of the shared weight\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    #####\n",
        "    D1, D2, D3 = optimal_structured_orthogonal_random_matrices(self.d, int(self.D/self.d + 1))\n",
        "    D1 = D1[:self.D]\n",
        "    D2 = D2[:self.D]\n",
        "    D3 = D3[:self.D]\n",
        "    self.D1 = D1.to(device)\n",
        "    self.D2 = D2.to(device)\n",
        "    self.D3 = D3.to(device)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = optimal_structured_orthogonal_random_calculation(self.theta, self.D1, self.D2, self.D3)\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    #the first thing to do at each call, I need to compute the weights for the whole network, from my subset of trainable weights.\n",
        "    #each layer is given its part.\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.linear(x, first_layer_theta_weight/math.sqrt(first_layer_theta_weight.shape[1]), first_layer_theta_bias/math.sqrt(first_layer_theta_weight.shape[1]))\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y"
      ],
      "metadata": {
        "id": "sgv0iKSv3FBs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myRandomFeaturesLeNet(nn.Module):\n",
        "  def __init__(self, d, in_channels = 1, out_channels = 16, input_dimension = 28, n_convolutions = 2, hidden_dim = 120, n_hidden_layers = 2, output_dim = 10, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_convolutions = n_convolutions\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.input_dimension = input_dimension\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.flatten_dim = int(out_channels*(input_dimension/2**n_convolutions)*(input_dimension/2**n_convolutions))\n",
        "\n",
        "    first_convolution_weight_D = 6* in_channels*5*5\n",
        "    first_convolution_bias_D = 6\n",
        "    second_convolution_weight_D = out_channels*6*5*5\n",
        "    second_convolution_bias_D = out_channels\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = (first_convolution_weight_D + first_convolution_bias_D + second_convolution_weight_D + second_convolution_bias_D + hidden_layers_weight_D*(n_hidden_layers-1) +\n",
        "    hidden_layers_bias_D*n_hidden_layers + self.flatten_dim*self.hidden_dim + last_layer_weight_D + last_layer_bias_D)\n",
        "\n",
        "    #counters are, start included, end excluded\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_convolution_weight_D\n",
        "    self.first_convolution_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_convolution_bias_D\n",
        "    self.first_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_weight_D\n",
        "    self.second_convolution_weight_edges = ((start_counter,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += second_convolution_bias_D\n",
        "    self.second_convolution_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      if i == 0:\n",
        "        end_counter += self.flatten_dim*hidden_dim\n",
        "\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "      else:\n",
        "        end_counter += hidden_layers_weight_D\n",
        "        self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "        end_counter += hidden_layers_bias_D\n",
        "        self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "        start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    ####\n",
        "    D1, D2, D3 = optimal_structured_orthogonal_random_matrices(self.d, int(self.D/self.d + 1))\n",
        "    D1 = D1[:self.D]\n",
        "    D2 = D2[:self.D]\n",
        "    D3 = D3[:self.D]\n",
        "    self.D1 = D1.to(device)\n",
        "    self.D2 = D2.to(device)\n",
        "    self.D3 = D3.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = optimal_structured_orthogonal_random_calculation(self.theta, self.D1, self.D2, self.D3)\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    first_convolution_theta_weight = torch.reshape(big_theta[self.first_convolution_weight_edges[0]:self.first_convolution_weight_edges[1]], (6,self.in_channels,5,5))\n",
        "    first_convolution_theta_bias = big_theta[self.first_convolution_bias_edges[0]:self.first_convolution_bias_edges[1]]\n",
        "    second_convolution_theta_weight = torch.reshape(big_theta[self.second_convolution_weight_edges[0]:self.second_convolution_weight_edges[1]], (self.out_channels,6,5,5))\n",
        "    second_convolution_theta_bias = big_theta[self.second_convolution_bias_edges[0]:self.second_convolution_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      if i == 0:\n",
        "        hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.flatten_dim)))\n",
        "        hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "        continue\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.conv2d(x, first_convolution_theta_weight/math.sqrt(first_convolution_theta_weight.shape[1]*25), first_convolution_theta_bias/math.sqrt(first_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = F.conv2d(y, second_convolution_theta_weight/math.sqrt(second_convolution_theta_weight.shape[1]*25), second_convolution_theta_bias/math.sqrt(second_convolution_theta_weight.shape[1]*25), padding = \"same\")\n",
        "\n",
        "    y = F.avg_pool2d(y,2)\n",
        "    y = F.tanh(y)\n",
        "    y = torch.flatten(y, start_dim = -3)\n",
        "\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y"
      ],
      "metadata": {
        "id": "gXmnU6nf4Fv2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on MNIST"
      ],
      "metadata": {
        "id": "xY4jLJEjzp5u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0COdCqT2Wk"
      },
      "source": [
        "## import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten"
      ],
      "metadata": {
        "id": "FoHHb96Ujmxg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSjjLXrOVWBy"
      },
      "source": [
        "%%capture\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "## transformations\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "## download and load training dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "## download and load testing dataset\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_0Vjq2RHlph"
      },
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = myTransformLeNet(1000, device = device, transform = \"cosine\")\n",
        "model = model.to(device)\n",
        "\n",
        "model.theta = model.theta.to(dev)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_count = 0\n",
        "for i in model.parameters():\n",
        "  p_count+= i.nelement()\n",
        "p_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_RwO9J_a33r",
        "outputId": "ff50ba10-5dd0-41c0-f756-74654b3d131d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44IdrNNeIi_I"
      },
      "source": [
        "## compute accuracy\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E59hwZlAIVcL",
        "outputId": "fabe2a68-d953-4303-cdc8-ab075535788c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    model = model.train()\n",
        "\n",
        "    ## training step\n",
        "    for i, (images, labels) in enumerate(trainloader):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        ## forward + backprop + loss\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        ## update model params\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(logits, labels, BATCH_SIZE)\n",
        "\n",
        "    model.eval()\n",
        "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
        "          %(epoch, train_running_loss / i, train_acc/i))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 1.9346 | Train Accuracy: 49.56\n",
            "Epoch: 1 | Loss: 1.3612 | Train Accuracy: 71.61\n",
            "Epoch: 2 | Loss: 1.1397 | Train Accuracy: 78.22\n",
            "Epoch: 3 | Loss: 1.0288 | Train Accuracy: 80.43\n",
            "Epoch: 4 | Loss: 0.9639 | Train Accuracy: 81.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU5WR0BTUHv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c5537c-ee64-4183-af13-e65a0cc8b84a"
      },
      "source": [
        "test_acc = 0.0\n",
        "for i, (images, labels) in enumerate(testloader, 0):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "\n",
        "print('Test Accuracy: %.2f'%( test_acc/i))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFWoG0-tKi_n"
      },
      "source": [
        "Training on CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSvDOrqALMro",
        "outputId": "aaa83035-dfc3-43f4-c8de-ca78fae11edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 35142118.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "eGcGPKSyLQ_W"
      },
      "outputs": [],
      "source": [
        "net = myTransformLeNet(20000, in_channels = 3, input_dimension = 32, device = dev)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "net = net.to(dev)\n",
        "#net.theta = net.theta.to(dev)\n",
        "#net.projection = net.projection.to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKQRviFhr4Au",
        "outputId": "eee75003-b03d-4605-dacb-e8ed0f5ab8e0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141602"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ksy2qsRLTY4",
        "outputId": "7a8598b0-a694-4abd-fd94-786897a51221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.318\n",
            "[1,  4000] loss: 2.312\n",
            "[1,  6000] loss: 2.305\n",
            "[1,  8000] loss: 2.298\n",
            "[1, 10000] loss: 2.290\n",
            "[1, 12000] loss: 2.279\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        labels = labels/10\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        inputs = inputs.to(dev)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(dev)\n",
        "        #breakpoint()\n",
        "        outputs = net(inputs)\n",
        "        outputs = F.softmax(outputs, dim = 1)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "        outputs = outputs.to(dev)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinforcement Learning"
      ],
      "metadata": {
        "id": "HIUrxiOQWc1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverted Pendulum"
      ],
      "metadata": {
        "id": "WCoyX_u-V599"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_pxHnd6hLemn"
      },
      "outputs": [],
      "source": [
        "#Two different Reinforcement Learning problems were experimented with\n",
        "#the first one is Inverted Pendulum.\n",
        "#I used this tutorial as reference https://pytorch.org/rl/tutorials/coding_ppo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HFTfHVIRL-0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73d3bef-b4f2-47f8-b469-a59b35831111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchrl\n",
            "  Downloading torchrl-0.2.1-cp310-cp310-manylinux1_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (23.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1)\n",
            "Collecting tensordict>=0.2.0 (from torchrl)\n",
            "  Downloading tensordict-0.2.1-cp310-cp310-manylinux1_x86_64.whl (986 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m986.5/986.5 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->torchrl) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->torchrl) (1.3.0)\n",
            "Installing collected packages: tensordict, torchrl\n",
            "Successfully installed tensordict-0.2.1 torchrl-0.2.1\n",
            "Requirement already satisfied: gym[mujoco] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (0.0.8)\n",
            "Collecting mujoco==2.2.0 (from gym[mujoco])\n",
            "  Downloading mujoco-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gym[mujoco]) (2.31.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco==2.2.0->gym[mujoco]) (1.4.0)\n",
            "Collecting glfw (from mujoco==2.2.0->gym[mujoco])\n",
            "  Downloading glfw-2.6.2-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco==2.2.0->gym[mujoco]) (3.1.7)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gym[mujoco]) (9.4.0)\n",
            "Installing collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.6.2 mujoco-2.2.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torchrl\n",
        "!pip3 install gym[mujoco]\n",
        "!pip3 install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "jWMj4-1MMAqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9f7584-3243-4ce8-8f8b-70943ce67133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchrl/__init__.py:32: UserWarning: failed to set start method to spawn, and current start method for mp is fork.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torch import nn\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (\n",
        "    Compose,\n",
        "    DoubleToFloat,\n",
        "    ObservationNorm,\n",
        "    StepCounter,\n",
        "    TransformedEnv,\n",
        ")\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torch import nn\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (\n",
        "    Compose,\n",
        "    DoubleToFloat,\n",
        "    ObservationNorm,\n",
        "    StepCounter,\n",
        "    TransformedEnv,\n",
        ")\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "b5WeU0ynw8I7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"# if not torch.has_cuda else \"cuda:0\"\n",
        "num_cells = 16  # number of cells in each layer i.e. output dim.\n",
        "lr = 3e-4\n",
        "max_grad_norm = 1.0\n",
        "d = 20\n",
        "#restart"
      ],
      "metadata": {
        "id": "BB17Gmlpw-sq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_skip = 1\n",
        "frames_per_batch = 1000 // frame_skip\n",
        "# For a complete training, bring the number of frames up to 1M\n",
        "total_frames = 10_000 // frame_skip"
      ],
      "metadata": {
        "id": "NRt2c06cxA5W"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_batch_size = 64  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
        "num_epochs = 10  # optimisation steps per batch of data collected\n",
        "clip_epsilon = (\n",
        "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
        ")\n",
        "gamma = 0.99\n",
        "lmbda = 0.95\n",
        "entropy_eps = 1e-4"
      ],
      "metadata": {
        "id": "IHthKYDGxC7J"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_env = GymEnv(\"InvertedDoublePendulum-v4\", device=device, frame_skip=frame_skip)"
      ],
      "metadata": {
        "id": "VVHIA_PmxFDL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    Compose(\n",
        "        # normalize observations\n",
        "        ObservationNorm(in_keys=[\"observation\"]),\n",
        "        DoubleToFloat(\n",
        "            in_keys=[\"observation\"],\n",
        "        ),\n",
        "        StepCounter(),\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "sMOB0sDGxHwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2621f53e-a3b3-4e89-9d4d-6ca2c0bda677"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)"
      ],
      "metadata": {
        "id": "KgLsv9tLxJ5X"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"normalization constant shape:\", env.transform[0].loc.shape)"
      ],
      "metadata": {
        "id": "ls5n7_lqxMK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202bb2d6-cca4-4c8e-c92a-a82b8bb9341f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalization constant shape: torch.Size([11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observation_spec:\", env.observation_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "print(\"done_spec:\", env.done_spec)\n",
        "print(\"action_spec:\", env.action_spec)\n",
        "print(\"state_spec:\", env.state_spec)"
      ],
      "metadata": {
        "id": "-F3wPnolxOZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e65aea0-07cb-4c76-d149-b44fd60d54f4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation_spec: CompositeSpec(\n",
            "    observation: UnboundedContinuousTensorSpec(\n",
            "        shape=torch.Size([11]),\n",
            "        space=None,\n",
            "        device=cpu,\n",
            "        dtype=torch.float32,\n",
            "        domain=continuous),\n",
            "    step_count: BoundedTensorSpec(\n",
            "        shape=torch.Size([1]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.int64,\n",
            "        domain=continuous), device=cpu, shape=torch.Size([]))\n",
            "reward_spec: UnboundedContinuousTensorSpec(\n",
            "    shape=torch.Size([1]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "    device=cpu,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n",
            "done_spec: CompositeSpec(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([1]),\n",
            "        space=DiscreteBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([1]),\n",
            "        space=DiscreteBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    truncated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([1]),\n",
            "        space=DiscreteBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete), device=cpu, shape=torch.Size([]))\n",
            "action_spec: BoundedTensorSpec(\n",
            "    shape=torch.Size([1]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "    device=cpu,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n",
            "state_spec: CompositeSpec(\n",
            "    step_count: BoundedTensorSpec(\n",
            "        shape=torch.Size([1]),\n",
            "        space=ContinuousBox(\n",
            "            low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, contiguous=True),\n",
            "            high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, contiguous=True)),\n",
            "        device=cpu,\n",
            "        dtype=torch.int64,\n",
            "        domain=continuous), device=cpu, shape=torch.Size([]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_env_specs(env)"
      ],
      "metadata": {
        "id": "GYX97igqxQrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f2092b-81ce-4196-e45b-1a91eb8306f2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check_env_specs succeeded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rollout = env.rollout(3)\n",
        "print(\"rollout of three steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
      ],
      "metadata": {
        "id": "wXVOzQv-xTJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5fcaf95-6f37-4e64-eab4-885cd44c5133"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rollout of three steps: TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([3, 11]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                step_count: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([3]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([3, 11]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([3]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n",
            "Shape of the rollout TensorDict: torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#actor_net = nn.Sequential(\n",
        "#    nn.LazyLinear(num_cells, device=device),\n",
        "#    nn.Tanh(),\n",
        "#    nn.LazyLinear(num_cells, device=device),\n",
        "#    nn.Tanh(),\n",
        "#    nn.LazyLinear(num_cells, device=device),\n",
        "#    nn.Tanh(),\n",
        "#    nn.LazyLinear(2 * env.action_spec.shape[-1], device=device),\n",
        "#    NormalParamExtractor(),\n",
        "#)"
      ],
      "metadata": {
        "id": "RIGf5gHsxWAG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_actor_linear(nn.Module): #this is a fully connected model,\n",
        "  def __init__(self, input_dimension, d, n_hidden_layers = 2, hidden_dim = 256, output_dim = 2* env.action_spec.shape[-1]):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.output_dim = output_dim\n",
        "    self.device = \"cpu\"\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.projection = self.projection.to(device)\n",
        "    ####\n",
        "    self.param_extractor = NormalParamExtractor()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.linear(x, first_layer_theta_weight/math.sqrt(first_layer_theta_weight.shape[1]), first_layer_theta_bias/math.sqrt(first_layer_theta_weight.shape[1]))\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    ####\n",
        "    y = self.param_extractor(y)\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "WsqV5zcG5mIf"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_net = my_actor_linear(11,d, hidden_dim = num_cells)\n",
        "my_actor_net = actor_net"
      ],
      "metadata": {
        "id": "NX2z8kW7bwXF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_module = TensorDictModule(\n",
        "    actor_net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"]\n",
        ")"
      ],
      "metadata": {
        "id": "4mhldlw6xYU7"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_module = ProbabilisticActor(\n",
        "    module=policy_module,\n",
        "    spec=env.action_spec,\n",
        "    in_keys=[\"loc\", \"scale\"],\n",
        "    distribution_class=TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"min\": env.action_spec.space.minimum,\n",
        "        \"max\": env.action_spec.space.maximum,\n",
        "    },\n",
        "    return_log_prob=True,\n",
        "    # we'll need the log-prob for the numerator of the importance weights\n",
        ")"
      ],
      "metadata": {
        "id": "A11ooH-2xaqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75bf4432-faa0-40ee-ad60-fb43f74df284"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchrl/data/tensor_specs.py:378: DeprecationWarning: <class 'torchrl.data.tensor_specs.ContinuousBox'>.minimum is going to be deprecated in favour of <class 'torchrl.data.tensor_specs.ContinuousBox'>.low\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchrl/data/tensor_specs.py:386: DeprecationWarning: <class 'torchrl.data.tensor_specs.ContinuousBox'>.maximum is going to be deprecated in favour of <class 'torchrl.data.tensor_specs.ContinuousBox'>.low\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "my_policy_module = TensorDictModule(\n",
        "    my_actor_net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"]\n",
        ")\n",
        "#might need to modify this"
      ],
      "metadata": {
        "id": "3EreuHosiEve"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_actor_net._modules"
      ],
      "metadata": {
        "id": "0OlkqjptoHw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016cbfca-ec32-47f5-fa96-6999892e1ef7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('param_extractor', NormalParamExtractor())])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "my_policy_module = ProbabilisticActor(\n",
        "    module=my_policy_module,\n",
        "    spec=env.action_spec,\n",
        "    in_keys=[\"loc\", \"scale\"],\n",
        "    distribution_class=TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"min\": env.action_spec.space.minimum,\n",
        "        \"max\": env.action_spec.space.maximum,\n",
        "    },\n",
        "    return_log_prob=True,\n",
        "    # we'll need the log-prob for the numerator of the importance weights\n",
        ")"
      ],
      "metadata": {
        "id": "Xod0MEViiF7r"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_net = nn.Sequential(\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(num_cells, device=device),\n",
        "    nn.Tanh(),\n",
        "    nn.LazyLinear(1, device=device),\n",
        ")\n",
        "\n",
        "value_module = ValueOperator(\n",
        "    module=value_net,\n",
        "    in_keys=[\"observation\"],\n",
        ")"
      ],
      "metadata": {
        "id": "kGAt6ADBxc9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2754e391-8df8-46c8-83ef-a97f49a2756d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPWsgCS_cKPV"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running policy:\", policy_module(env.reset()))\n",
        "print(\"Running value:\", value_module(env.reset()))"
      ],
      "metadata": {
        "id": "WAGAYDjPxfpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca8b3af-e628-45e0-d80b-82bce7b78eb4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running policy: TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        loc: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([11]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        sample_log_prob: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        scale: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n",
            "Running value: TensorDict(\n",
            "    fields={\n",
            "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([11]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        state_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy_module,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "H8kZAqATxiiM"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########\n",
        "my_collector = SyncDataCollector(\n",
        "    env,\n",
        "    my_policy_module,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "tQmWTkAnpbbp"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(frames_per_batch),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        ")"
      ],
      "metadata": {
        "id": "KrWiKccgxkw4"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advantage_module = GAE(\n",
        "    gamma=gamma, lmbda=lmbda, value_network=value_module, average_gae=True\n",
        ")\n",
        "\n",
        "loss_module = ClipPPOLoss(\n",
        "    actor=policy_module,\n",
        "    critic=value_module,\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_bonus=bool(entropy_eps),\n",
        "    entropy_coef=entropy_eps,\n",
        "    # these keys match by default but we set this for completeness\n",
        "    value_target_key=advantage_module.value_target_key,\n",
        "    critic_coef=1.0,\n",
        "    gamma=0.99,\n",
        "    loss_critic_type=\"smooth_l1\",\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optim, total_frames // frames_per_batch, 0.0\n",
        ")"
      ],
      "metadata": {
        "id": "yo5D8qZ0xnDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9223c9e-7a7f-4e6f-d005-e7486b353c10"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchrl/objectives/ppo.py:298: DeprecationWarning: Passing gamma / lambda parameters through the loss constructor is deprecated and will be removed soon. To customize your value function, run `loss_module.make_value_estimator(ValueEstimators.<value_fun>, gamma=val)`.\n",
            "  warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/torchrl/objectives/common.py:123: DeprecationWarning: Setting 'value_target' via the constructor is deprecated, use .set_keys(<key>='some_key') instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, policy_module)\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
        "\n",
        "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
        "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "d93N8sK0xseo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79c98f2-9576-4d47-e5a5-e2a574a6129a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval cumulative reward:  82.7972 (init:  82.7972), eval step-count: 8, average reward= 9.0714 (init= 9.0552), step count (max): 12, lr policy:  0.0000: 100%|██████████| 10000/10000 [00:50<00:00, 261.00it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(logs[\"reward\"])\n",
        "plt.title(\"training rewards (average)\")\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(logs[\"step_count\"])\n",
        "plt.title(\"Max step count (training)\")\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(logs[\"eval reward (sum)\"])\n",
        "plt.title(\"Return (test)\")\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(logs[\"eval step_count\"])\n",
        "plt.title(\"Max step count (test)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "auU6-zYww6ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "31dcc470-e3e6-4a0f-efc3-a2abf4d5df4b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "logs = defaultdict(list)\n",
        "pbar = tqdm(total=total_frames * frame_skip)\n",
        "eval_str = \"\"\n",
        "\n",
        "# We iterate over the collector until it reaches the total number of frames it was\n",
        "# designed to collect:\n",
        "for i, tensordict_data in enumerate(my_collector):\n",
        "    # we now have a batch of data to work with. Let's learn something from it.\n",
        "    for _ in range(num_epochs):\n",
        "        # We'll need an \"advantage\" signal to make PPO work.\n",
        "        # We re-compute it at each epoch as its value depends on the value\n",
        "        # network which is updated in the inner loop.\n",
        "        with torch.no_grad():\n",
        "            advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            # Optimization: backward, grad clipping and optim step\n",
        "            loss_value.backward()\n",
        "            # this is not strictly mandatory but it's good practice to keep\n",
        "            # your gradient norm bounded\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    pbar.update(tensordict_data.numel() * frame_skip)\n",
        "    cum_reward_str = (\n",
        "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
        "    )\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
        "    if i % 10 == 0:\n",
        "        # We evaluate the policy once every 10 batches of data.\n",
        "        # Evaluation is rather simple: execute the policy without exploration\n",
        "        # (take the expected value of the action distribution) for a given\n",
        "        # number of steps (1000, which is our env horizon).\n",
        "        # The ``rollout`` method of the env can take a policy as argument:\n",
        "        # it will then execute this policy at each step.\n",
        "        with set_exploration_type(ExplorationType.MEAN), torch.no_grad():\n",
        "            # execute a rollout with the trained policy\n",
        "            eval_rollout = env.rollout(1000, policy_module)\n",
        "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
        "            logs[\"eval reward (sum)\"].append(\n",
        "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
        "            )\n",
        "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
        "            eval_str = (\n",
        "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
        "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
        "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
        "            )\n",
        "            del eval_rollout\n",
        "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
        "\n",
        "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
        "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "_WNTQBw1puUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c655b7a4-3d85-421a-ab8e-488fedbbcc11"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "eval cumulative reward:  82.7972 (init:  82.7972), eval step-count: 8, average reward= 9.0714 (init= 9.0552), step count (max): 12, lr policy:  0.0000: 100%|██████████| 10000/10000 [00:51<00:00, 194.41it/s]\n",
            "\n",
            " 10%|█         | 1000/10000 [00:06<01:01, 146.23it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0733 (init= 9.0733), step count (max): 19, lr policy:  0.0000:  10%|█         | 1000/10000 [00:06<01:01, 146.23it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0733 (init= 9.0733), step count (max): 19, lr policy:  0.0000:  20%|██        | 2000/10000 [00:10<00:38, 206.96it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0792 (init= 9.0733), step count (max): 12, lr policy:  0.0000:  20%|██        | 2000/10000 [00:10<00:38, 206.96it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0792 (init= 9.0733), step count (max): 12, lr policy:  0.0000:  30%|███       | 3000/10000 [00:14<00:30, 227.61it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0635 (init= 9.0733), step count (max): 9, lr policy:  0.0000:  30%|███       | 3000/10000 [00:14<00:30, 227.61it/s] \u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0635 (init= 9.0733), step count (max): 9, lr policy:  0.0000:  40%|████      | 4000/10000 [00:17<00:24, 245.16it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0689 (init= 9.0733), step count (max): 11, lr policy:  0.0001:  40%|████      | 4000/10000 [00:17<00:24, 245.16it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0689 (init= 9.0733), step count (max): 11, lr policy:  0.0001:  50%|█████     | 5000/10000 [00:20<00:18, 264.56it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0684 (init= 9.0733), step count (max): 11, lr policy:  0.0001:  50%|█████     | 5000/10000 [00:20<00:18, 264.56it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0684 (init= 9.0733), step count (max): 11, lr policy:  0.0001:  60%|██████    | 6000/10000 [00:24<00:15, 259.87it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0706 (init= 9.0733), step count (max): 11, lr policy:  0.0002:  60%|██████    | 6000/10000 [00:24<00:15, 259.87it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0706 (init= 9.0733), step count (max): 11, lr policy:  0.0002:  70%|███████   | 7000/10000 [00:28<00:11, 258.75it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0653 (init= 9.0733), step count (max): 9, lr policy:  0.0002:  70%|███████   | 7000/10000 [00:28<00:11, 258.75it/s] \u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0653 (init= 9.0733), step count (max): 9, lr policy:  0.0002:  80%|████████  | 8000/10000 [00:32<00:07, 270.11it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0738 (init= 9.0733), step count (max): 11, lr policy:  0.0002:  80%|████████  | 8000/10000 [00:32<00:07, 270.11it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0738 (init= 9.0733), step count (max): 11, lr policy:  0.0002:  90%|█████████ | 9000/10000 [00:35<00:03, 281.13it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0642 (init= 9.0733), step count (max): 10, lr policy:  0.0003:  90%|█████████ | 9000/10000 [00:35<00:03, 281.13it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0642 (init= 9.0733), step count (max): 10, lr policy:  0.0003: 100%|██████████| 10000/10000 [00:39<00:00, 273.80it/s]\u001b[A\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0857 (init= 9.0733), step count (max): 11, lr policy:  0.0003: 100%|██████████| 10000/10000 [00:39<00:00, 273.80it/s]\u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAwid8RtMgtX"
      },
      "source": [
        "Cart Pole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ZmHJh64SMiBZ"
      },
      "outputs": [],
      "source": [
        "#The other Reinforcement Learning Problem that was experimented with is Cart Pole\n",
        "#I used this tutorial as reference\n",
        "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "AgLyEWxq4uhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6eb9b89c-8b18-4e29-dfa5-d4df0047a064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.1.0+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Installing collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.1.0\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "eval cumulative reward:  73.2791 (init:  73.2791), eval step-count: 7, average reward= 9.0857 (init= 9.0733), step count (max): 11, lr policy:  0.0003: 100%|██████████| 10000/10000 [00:53<00:00, 273.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.1.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373073 sha256=100eb18a4b9b0a84b922a3d5cf0ca4ef64a3f6d193e94ad7b59a8ba2f5c11db5\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n",
            "Collecting tianshou\n",
            "  Downloading tianshou-0.5.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.29.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tianshou) (4.66.1)\n",
            "Requirement already satisfied: numpy>1.16.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (1.23.5)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.14.1)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.1.0+cu118)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.56.4)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (3.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tianshou) (23.2)\n",
            "Collecting pettingzoo>=1.22 (from tianshou)\n",
            "  Downloading pettingzoo-1.24.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.8/840.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (0.0.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (67.7.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.31.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (2.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->tianshou) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->tianshou) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (3.2.2)\n",
            "Installing collected packages: pettingzoo, tianshou\n",
            "Successfully installed pettingzoo-1.24.1 tianshou-0.5.1\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2 (from gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py~=0.7.5 (from gym[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (6.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.66.1)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2023.7.22)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=ec8e1d269a59b5b0d6074d0a6ac0bb728a8722ea656f13781a66c154e86edd76\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: ale-py, AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: gym[accept-rom-license]: command not found\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.4.2)\n",
            "Collecting shimmy[atari]<1.0,>=0.1.0 (from gymnasium[accept-rom-license,atari])\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (4.66.1)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (0.6.1)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (6.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2023.7.22)\n",
            "Installing collected packages: ale-py, shimmy\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.7.5\n",
            "    Uninstalling ale-py-0.7.5:\n",
            "      Successfully uninstalled ale-py-0.7.5\n",
            "Successfully installed ale-py-0.8.1 shimmy-0.2.1\n",
            "Collecting envpool\n",
            "  Downloading envpool-0.8.4-cp310-cp310-manylinux_2_24_x86_64.whl (74.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-env>=1.4 (from envpool)\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gym>=0.18 in /usr/local/lib/python3.10/dist-packages (from envpool) (0.25.2)\n",
            "Requirement already satisfied: gymnasium>=0.26 in /usr/local/lib/python3.10/dist-packages (from envpool) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from envpool) (1.23.5)\n",
            "Collecting types-protobuf>=3.17.3 (from envpool)\n",
            "  Downloading types_protobuf-4.24.0.4-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from envpool) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from envpool) (23.2)\n",
            "Collecting optree>=0.6.0 (from envpool)\n",
            "  Downloading optree-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from dm-env>=1.4->envpool) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-env>=1.4->envpool) (0.1.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.18->envpool) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.18->envpool) (0.0.8)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26->envpool) (0.0.4)\n",
            "Installing collected packages: types-protobuf, optree, dm-env, envpool\n",
            "Successfully installed dm-env-1.6 envpool-0.8.4 optree-0.9.2 types-protobuf-4.24.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install stable_baselines3\n",
        "!pip install swig\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install tianshou\n",
        "!pip install \"gym[atari, accept-rom-license]\"\n",
        "!gym[accept-rom-license]\n",
        "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
        "!pip install envpool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "svR1_jsd5JnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d433f2-6441-4899-df98-45eaa17780a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[classic_control] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (2.5.2)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip3 install gymnasium[classic_control]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "0V2kveZW5X8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbed549-5043-4876-bfab-d56b471142d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if GPU is to be used\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Wa7gS2Cc_fEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd44ac8-3e59-4e4b-e4ce-1773dabf78c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "dqn_d = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "WBYYtgWg5Z7Q"
      },
      "outputs": [],
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "yUdKtbqo7pHH"
      },
      "outputs": [],
      "source": [
        "#class DQN(nn.Module):\n",
        "#\n",
        "#    def __init__(self, n_observations, n_actions):\n",
        "#        super(DQN, self).__init__()\n",
        "#        self.layer1 = nn.Linear(n_observations, 128)\n",
        "#        self.layer2 = nn.Linear(128, 128)\n",
        "#        self.layer3 = nn.Linear(128, n_actions)\n",
        "#\n",
        "#    # Called with either one element to determine next action, or a batch\n",
        "#    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "#    def forward(self, x):\n",
        "#        x = F.relu(self.layer1(x))\n",
        "#        x = F.relu(self.layer2(x))\n",
        "#        return self.layer3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "kW_tjw3k-BQM"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, input_dimension, output_dim, d = dqn_d, n_hidden_layers = 2, hidden_dim = 128, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "    self.d = d\n",
        "    self.theta = nn.Parameter(torch.randn(d))\n",
        "    self.n_hidden_layers = n_hidden_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_dimension = input_dimension\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    first_layer_weight_D = input_dimension * hidden_dim\n",
        "    first_layer_bias_D = hidden_dim\n",
        "    hidden_layers_weight_D = hidden_dim * hidden_dim\n",
        "    hidden_layers_bias_D = hidden_dim\n",
        "    last_layer_weight_D = hidden_dim * output_dim\n",
        "    last_layer_bias_D = output_dim\n",
        "\n",
        "    self.D = first_layer_weight_D + first_layer_bias_D + hidden_layers_weight_D*n_hidden_layers + hidden_layers_bias_D*n_hidden_layers + last_layer_weight_D + last_layer_bias_D\n",
        "    self.projection = dense_matrix(self.D, self.d)\n",
        "\n",
        "    start_counter = 0\n",
        "    end_counter = 0\n",
        "    end_counter += first_layer_weight_D\n",
        "    self.first_layer_weight_edges = ((0,end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter += first_layer_bias_D\n",
        "    self.first_layer_bias_edges = (start_counter, end_counter)\n",
        "    start_counter = end_counter\n",
        "    self.hidden_layers_weight_edges = []\n",
        "    self.hidden_layers_bias_edges = []\n",
        "    for i in range(n_hidden_layers):\n",
        "      end_counter += hidden_layers_weight_D\n",
        "      self.hidden_layers_weight_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "      end_counter += hidden_layers_bias_D\n",
        "      self.hidden_layers_bias_edges.append((start_counter, end_counter))\n",
        "      start_counter = end_counter\n",
        "\n",
        "    end_counter += last_layer_weight_D\n",
        "    self.last_layer_weight_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "    end_counter +=last_layer_bias_D\n",
        "    self.last_layer_bias_edges = ((start_counter, end_counter))\n",
        "    start_counter = end_counter\n",
        "\n",
        "    self.projection = self.projection.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "    big_theta = self.projection @ self.theta\n",
        "    big_theta = big_theta/big_theta.std()\n",
        "    big_theta = big_theta - big_theta.mean()\n",
        "\n",
        "    first_layer_theta_weight = torch.reshape(big_theta[self.first_layer_weight_edges[0]:self.first_layer_weight_edges[1]], (self.hidden_dim, self.input_dimension))\n",
        "    first_layer_theta_bias = big_theta[self.first_layer_bias_edges[0]:self.first_layer_bias_edges[1]]\n",
        "    hidden_layers_theta_weight = []\n",
        "    hidden_layers_theta_bias = []\n",
        "    for i in range(self.n_hidden_layers):\n",
        "\n",
        "      hidden_layers_theta_weight.append(torch.reshape(big_theta[self.hidden_layers_weight_edges[i][0]:self.hidden_layers_weight_edges[i][1]],(self.hidden_dim, self.hidden_dim)))\n",
        "      hidden_layers_theta_bias.append(big_theta[self.hidden_layers_bias_edges[i][0]:self.hidden_layers_bias_edges[i][1]])\n",
        "\n",
        "    last_layer_theta_weight = torch.reshape(big_theta[self.last_layer_weight_edges[0]:self.last_layer_weight_edges[1]], (self.output_dim, self.hidden_dim))\n",
        "    last_layer_theta_bias = big_theta[self.last_layer_bias_edges[0]:self.last_layer_bias_edges[1]]\n",
        "\n",
        "    y = F.linear(x, first_layer_theta_weight/math.sqrt(first_layer_theta_weight.shape[1]), first_layer_theta_bias/math.sqrt(first_layer_theta_weight.shape[1]))\n",
        "    y = F.relu(y)\n",
        "    for i in range(self.n_hidden_layers):\n",
        "      y = F.linear(y,hidden_layers_theta_weight[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]), hidden_layers_theta_bias[i]/math.sqrt(hidden_layers_theta_weight[i].shape[1]))\n",
        "      y = F.relu(y)\n",
        "\n",
        "    y = F.linear(y, last_layer_theta_weight/math.sqrt(last_layer_theta_weight.shape[1]), last_layer_theta_bias/math.sqrt(last_layer_theta_weight.shape[1]))\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "rQ-hIaSp5cwB"
      },
      "outputs": [],
      "source": [
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "uyNpCo2R5gi8"
      },
      "outputs": [],
      "source": [
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the ``AdamW`` optimizer\n",
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 1000\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state, info = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "#optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "optimizer = optim.AdamW([policy_net.theta], lr=LR, amsgrad=True)\n",
        "\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations(show_result=False):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "iq3Tb30p5kBq"
      },
      "outputs": [],
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_([policy_net.theta], 100)\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "QSKXoMzM5nEd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "1138fef4-6310-417b-cf44-a3a388bd0a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    num_episodes = 600\n",
        "else:\n",
        "    num_episodes = 50\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    state, info = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    for t in count():\n",
        "        action = select_action(state)\n",
        "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        # θ′ ← τ θ + (1 −τ )θ′\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            break\n",
        "\n",
        "print('Complete')\n",
        "plot_durations(show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    }
  ]
}